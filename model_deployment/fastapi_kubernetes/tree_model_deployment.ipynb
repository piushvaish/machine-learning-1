{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tree-Model-Deployment\" data-toc-modified-id=\"Tree-Model-Deployment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tree Model Deployment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Calling-the-API\" data-toc-modified-id=\"Calling-the-API-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Calling the API</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2020-03-17 17:29:50 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 7.9.0\n",
      "\n",
      "numpy 1.18.1\n",
      "pandas 0.25.0\n",
      "sklearn 0.21.2\n",
      "lightgbm 2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingyuliu/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "\n",
    "# prevent scientific notations\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try and keep the data, feature engineering, model training part as short as possible as the main focus of the repo is to build a service on top of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "data shape:  (20640, 8)\n",
      "description:\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cal_housing = fetch_california_housing()\n",
    "print('feature names:', cal_housing.feature_names)\n",
    "print('data shape: ', cal_housing.data.shape)\n",
    "\n",
    "print('description:')\n",
    "print(cal_housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 123\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cal_housing.data,\n",
    "    cal_housing.target,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "print(cal_housing.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the [LightGBM Python Quickstart](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html) to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x107a544a8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_train, y_train,\n",
    "                     feature_name=cal_housing.feature_names,\n",
    "                     free_raw_data=False)\n",
    "dtest = lgb.Dataset(X_test, y_test,\n",
    "                    feature_name=cal_housing.feature_names,\n",
    "                    free_raw_data=False)\n",
    "dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[50]\ttraining's rmse: 0.480561\tvalid_1's rmse: 0.506189\n",
      "[100]\ttraining's rmse: 0.429389\tvalid_1's rmse: 0.475466\n",
      "[150]\ttraining's rmse: 0.40234\tvalid_1's rmse: 0.464791\n",
      "[200]\ttraining's rmse: 0.382479\tvalid_1's rmse: 0.458266\n",
      "[250]\ttraining's rmse: 0.367124\tvalid_1's rmse: 0.45328\n",
      "[300]\ttraining's rmse: 0.353168\tvalid_1's rmse: 0.449646\n",
      "[350]\ttraining's rmse: 0.34103\tvalid_1's rmse: 0.446907\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's rmse: 0.34038\tvalid_1's rmse: 0.446728\n"
     ]
    }
   ],
   "source": [
    "params_constraint = {\n",
    "    'nthread': 6,\n",
    "    'seed': 0,\n",
    "    'metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 5\n",
    "}\n",
    " \n",
    "evals_result = {}\n",
    "model = lgb.train(\n",
    "    params_constraint, dtrain,\n",
    "    valid_sets=[dtrain, dtest],\n",
    "    evals_result=evals_result,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick evaluation of our regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_score(y_true, y_score):\n",
    "    \"\"\"Mean Absolute Percentage Error (MAPE).\"\"\"\n",
    "    mask = y_true != 0\n",
    "    y_true = y_true[mask]\n",
    "    y_score = y_score[mask]\n",
    "    mape = np.abs(y_true - y_score) / y_true\n",
    "    return np.mean(mape)\n",
    "\n",
    "\n",
    "def compute_score(model, dataset, verbose=True):\n",
    "    \"\"\"\n",
    "    Computes the model evaluation score (r2, rmse, mape) for the\n",
    "    input model and dataset.\n",
    "    \"\"\"\n",
    "    y_true = dataset.get_label()\n",
    "    y_score = model.predict(dataset.get_data())\n",
    "\n",
    "    r2 = round(metrics.r2_score(y_true, y_score), 3)\n",
    "    rmse = round(np.sqrt(metrics.mean_squared_error(y_true, y_score)), 3)\n",
    "    mape = round(mape_score(y_true, y_score), 3)\n",
    "    if verbose:\n",
    "        print('r2: ', r2)\n",
    "        print('rmse: ', rmse)\n",
    "        print('mape: ', mape)\n",
    "\n",
    "    return r2, rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.85\n",
      "rmse:  0.447\n",
      "mape:  0.166\n"
     ]
    }
   ],
   "source": [
    "r2, rmse, mape = compute_score(model, dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the trained model under the `app` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('app', 'model.txt')\n",
    "model.save_model(save_path, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the prediction between the model and the saved model matches. Here we pass in the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2418686 , 1.00175827, 1.48855899, ..., 0.75053102, 1.98354469,\n",
       "       3.65037742])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(dtest.get_data())\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2418686 , 1.00175827, 1.48855899, ..., 0.75053102, 1.98354469,\n",
       "       3.65037742])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = lgb.Booster(model_file=save_path)\n",
    "predictions = model_loaded.predict(dtest.get_data())\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform prediction for a single record. The caveat here is that `.predict` expects a 2d array, hence for single record prediction, we need to reshape it to 2d first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.79170000e+00,  4.00000000e+01,  4.95979899e+00,\n",
       "         1.03015075e+00,  1.03900000e+03,  2.61055276e+00,\n",
       "         3.82400000e+01, -1.22640000e+02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = dtest.get_data()[0].reshape(1, -1)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2418686])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding on to this section, we need to create the service first. Either follow the **Docker Container** section in the README to host the service locally through a container or power through the **Azure Kubernetes Cluster** section to host the service on Azure Kubernetes Cluster.\n",
    "\n",
    "Once we host the service, and can test it using the `request` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MedInc': 3.7917,\n",
       " 'HouseAge': 40.0,\n",
       " 'AveRooms': 4.959798994974874,\n",
       " 'AveBedrms': 1.0301507537688441,\n",
       " 'Population': 1039.0,\n",
       " 'AveOccup': 2.6105527638190953,\n",
       " 'Latitude': 38.24,\n",
       " 'Longitude': -122.64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = {\n",
    "#   \"MedInc\": 0,\n",
    "#   \"HouseAge\": 0,\n",
    "#   \"AveRooms\": 0,\n",
    "#   \"AveBedrms\": 0,\n",
    "#   \"Population\": 0,\n",
    "#   \"AveOccup\": 0,\n",
    "#   \"Latitude\": 0,\n",
    "#   \"Longitude\": 0\n",
    "# }\n",
    "\n",
    "data = {feature_name: value for feature_name, value in zip(cal_housing.feature_names, dtest.get_data()[0])}\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the url accordingly. And pass our features as a json body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 2.2418686032176747}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. for local deployment\n",
    "# url = 'http://127.0.0.1:8000/predict'\n",
    "\n",
    "# e.g. for local docker deployment\n",
    "# url = 'http://0.0.0.0:80/predict'\n",
    "\n",
    "# e.g. for azure kubernetes cluster deployment\n",
    "url = 'http://13.91.195.109:80/predict'\n",
    "\n",
    "raw_response = requests.post(url, data=json.dumps(data))\n",
    "raw_response.raise_for_status()\n",
    "response = json.loads(raw_response.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 µs ± 10.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# speed benchmark of the model\n",
    "model.predict(row)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.3 ms ± 882 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# speed benchmark of the model hosted as a service\n",
    "raw_response = requests.post(url, data=json.dumps(data))\n",
    "raw_response.raise_for_status()\n",
    "response = json.loads(raw_response.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've also implemented the endpoint for supporting batch calls, i.e. to get the scores for multiple records in a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MedInc': 3.7917,\n",
       "  'HouseAge': 40.0,\n",
       "  'AveRooms': 4.959798994974874,\n",
       "  'AveBedrms': 1.0301507537688441,\n",
       "  'Population': 1039.0,\n",
       "  'AveOccup': 2.6105527638190953,\n",
       "  'Latitude': 38.24,\n",
       "  'Longitude': -122.64},\n",
       " {'MedInc': 4.0217,\n",
       "  'HouseAge': 9.0,\n",
       "  'AveRooms': 5.804577464788732,\n",
       "  'AveBedrms': 1.0,\n",
       "  'Population': 1749.0,\n",
       "  'AveOccup': 3.079225352112676,\n",
       "  'Latitude': 36.09,\n",
       "  'Longitude': -119.05},\n",
       " {'MedInc': 4.0882,\n",
       "  'HouseAge': 12.0,\n",
       "  'AveRooms': 5.36036036036036,\n",
       "  'AveBedrms': 1.0705705705705706,\n",
       "  'Population': 3321.0,\n",
       "  'AveOccup': 4.986486486486487,\n",
       "  'Latitude': 32.85,\n",
       "  'Longitude': -116.98}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloads = []\n",
    "for data in dtest.get_data()[:3]:\n",
    "    payload = {feature_name: value for feature_name, value in zip(cal_housing.feature_names, data)}\n",
    "    payloads.append(payload)\n",
    "\n",
    "payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': [2.2418686032176747, 1.001758270797447, 1.4885589912546886]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://13.91.195.109:80/batch/predict'\n",
    "raw_response = requests.post(url, data=json.dumps(payloads))\n",
    "raw_response.raise_for_status()\n",
    "response = json.loads(raw_response.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.9 ms ± 1.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# speed benchmark of the model hosted as a service using the batch endpoint\n",
    "raw_response = requests.post(url, data=json.dumps(payloads))\n",
    "raw_response.raise_for_status()\n",
    "response = json.loads(raw_response.text)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
