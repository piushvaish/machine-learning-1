{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "noBz1XGlvMvY",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Quora-Insincere-Text-Classification\" data-toc-modified-id=\"Quora-Insincere-Text-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Quora Insincere Text Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing---Vocabulary-/-Pretrained-Word-Embedding\" data-toc-modified-id=\"Preprocessing---Vocabulary-/-Pretrained-Word-Embedding-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preprocessing - Vocabulary / Pretrained Word Embedding</a></span></li><li><span><a href=\"#Data-Loading\" data-toc-modified-id=\"Data-Loading-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Data Loading</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Prediction</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Submission</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "nUjA9iItvZWt",
    "outputId": "3a7e02c6-6323-416f-a8f6-1d8425945338"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('http://fonts.googleapis.com/css?family=Source+Code+Pro');\n",
       "@import url('http://fonts.googleapis.com/css?family=Vollkorn');\n",
       "@import url('http://fonts.googleapis.com/css?family=Arimo');\n",
       "@import url('http://fonts.googleapis.com/css?family=Fira_sans');\n",
       "    \n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.text_cell code {\n",
       "        background: transparent;\n",
       "        color: #000000;\n",
       "        font-weight: 600;\n",
       "        font-size: 12pt;\n",
       "        font-style: bold;\n",
       "        font-family:  'Source Code Pro', Consolas, monocco, monospace;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "\t}\n",
       "\t\n",
       "    div.input_area {\n",
       "        background: #F6F6F9;\n",
       "        border: 1px solid #586e75;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 30pt;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h2 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "        text-align: left;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200;\n",
       "        font-size: 16pt;\n",
       "        font-style: italic;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1.5em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h3 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200;\n",
       "        font-size: 14pt;\n",
       "        line-height: 100%;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 2em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    h4 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-weight: 100;\n",
       "        font-size: 14pt;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    h5 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200;\n",
       "        font-style: normal;\n",
       "        color: #1d3b84;\n",
       "        font-size: 16pt;\n",
       "        margin-bottom: 0em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Fira sans', verdana,arial,sans-serif;\n",
       "        line-height: 125%;\n",
       "        font-size: 115%;\n",
       "        text-align:justify;\n",
       "        text-justify:inter-word;\n",
       "    }\n",
       "    div.output_wrapper{\n",
       "        margin-top:0.2em;\n",
       "        margin-bottom:0.2em;\n",
       "    }\n",
       "\n",
       "    code{\n",
       "      font-size: 70%;\n",
       "    }\n",
       "    .rendered_html code{\n",
       "    background-color: transparent;\n",
       "    }\n",
       "    ul{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li li{\n",
       "        padding-left: 0.2em; \n",
       "        margin-bottom: 0.2em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    ol{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ol li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "    .rendered_html :hover {\n",
       "       text-decoration: none; \n",
       "    }\n",
       "    .rendered_html :visited {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :focus {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :active {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    } \n",
       "    hr {\n",
       "      color: #f3f3f3;\n",
       "      background-color: #f3f3f3;\n",
       "      height: 1px;\n",
       "    }\n",
       "    blockquote{\n",
       "      display:block;\n",
       "      background: #fcfcfc;\n",
       "      border-left: 5px solid #c76c0c;\n",
       "      font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "      width:680px;\n",
       "      padding: 10px 10px 10px 10px;\n",
       "      text-align:justify;\n",
       "      text-justify:inter-word;\n",
       "      }\n",
       "      blockquote p {\n",
       "        margin-bottom: 0;\n",
       "        line-height: 125%;\n",
       "        font-size: 100%;\n",
       "      }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "from formats import load_style\n",
    "load_style(plot_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "D7Er_4TmvMvb",
    "outputId": "fa5ce10c-262d-4073-9ad6-d2359e3223b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2020-01-30 22:28:14 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 7.9.0\n",
      "\n",
      "numpy 1.16.5\n",
      "pandas 0.25.0\n",
      "sklearn 0.21.2\n",
      "matplotlib 3.1.1\n",
      "torch 1.3.1\n",
      "keras 2.2.2\n",
      "spacy 2.1.6\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prevent scientific notations\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,matplotlib,torch,keras,spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jsNL1BSkDk7"
   },
   "source": [
    "# Quora Insincere Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "TCuTGylnvMvf",
    "outputId": "1fe5af5c-3086-41e3-a91c-77bf5b7e625a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeddings',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'embeddings.zip',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_dir = '.'\n",
    "data_dir = os.path.join('data', 'quora-insincere-questions-classification')\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "h2d6RMXWm-Lb",
    "outputId": "ceccf6cc-9616-4ca8-fa85-d559c2bcc0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available pretrained embeddings:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GoogleNews-vectors-negative300',\n",
       " 'paragram_300_sl999',\n",
       " 'glove.840B.300d',\n",
       " 'wiki-news-300d-1M']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('available pretrained embeddings:')\n",
    "embeddings_dir = os.path.join(data_dir, 'embeddings')\n",
    "os.listdir(embeddings_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "zr2sN6mwvMvi",
    "outputId": "166eb152-547b-493c-97d1-bfd50cf31527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data shape:  (1306122, 3)\n",
      "test shape: (375806, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "test_path = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "print('full data shape: ', df.shape)\n",
    "print('test shape:', df_test.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3j3xXNDnozij"
   },
   "source": [
    "We can observe an class imbalance, meaning out of all of questions provided, only 6% of them are labeled as insincere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "F3P3pJ0xvMvl",
    "outputId": "fec45c24-8a36-4755-e586-1449751775f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.938\n",
       "1   0.062\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_col = 'question_text'\n",
    "label_col = 'target'\n",
    "\n",
    "df[label_col].value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3o28hIMLxYS"
   },
   "source": [
    "## Preprocessing - Vocabulary / Pretrained Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZb1yAav20_D"
   },
   "source": [
    "We leverage spacy's tokenizer to tokenize our raw text into a space delimited text. As spacy's tokenizer is a lot more expensive compared to splitting on white-spaces, we'll perform it once for our raw text so we don't have to repeat this expensive process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HWTqkrZ2rxl"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner', 'tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A1Agj_J8Xedd",
    "outputId": "a34a958b-2a4d-4373-c0fa-cc056e8555a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [07:01<00:00, 3099.87it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = df[label_col].values\n",
    "\n",
    "texts = []\n",
    "for text in tqdm(df[text_col]):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    tokenized_text = ' '.join(token.text for token in doc)\n",
    "    texts.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "aZmJ3DXyCI5J",
    "outputId": "3bc30af0-a4ff-44e2-ab8f-71785473001e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  1175509\n",
      "validation size:  130613\n"
     ]
    }
   ],
   "source": [
    "random_state = 1234\n",
    "val_split = 0.1\n",
    "\n",
    "texts_train, texts_val, y_train, y_val = train_test_split(\n",
    "    texts, labels,\n",
    "    test_size=val_split,\n",
    "    random_state=random_state)\n",
    "\n",
    "print('train size: ', len(texts_train))\n",
    "print('validation size: ', len(texts_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QExp-oH0scp"
   },
   "source": [
    "Here we've implemented a custom tokenizer, the motivation for doing so was due to the fact at the time of writing this, keras' tokenizer did not have a `min_freq` option, meaning we could not tell the tokenizer to only retain words/tokens that have appeared in the corpus for more than `min_freq` number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0d62m_pS26mW"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "\n",
    "    def __init__(self, tokenizer=None, max_vocab_size=None, min_count=2,\n",
    "                 unk_token=None, pad_token='<pad>'):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.min_count = min_count\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.unk_token = unk_token\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def fit(self, texts):\n",
    "        if self.tokenizer is None:\n",
    "            self.tokenizer_ = whitespace_tokenizer\n",
    "        else:\n",
    "            self.tokenizer_ = self.tokenizer\n",
    "\n",
    "        index2word, word2index = self.learn_vocab(texts)\n",
    "        self.index2word_ = index2word\n",
    "        self.word2index_ = word2index\n",
    "        self.vocab_size_ = len(word2index)\n",
    "        return self\n",
    "\n",
    "    def learn_vocab(self, texts):\n",
    "        tokenizer = self.tokenizer_\n",
    "\n",
    "        word_counts = {}\n",
    "        for text in texts:\n",
    "            words = tokenizer(text)\n",
    "            for word in words:\n",
    "                count = word_counts.get(word, 0)\n",
    "                word_counts[word] = count + 1\n",
    "\n",
    "        sorted_word_counts = sorted(word_counts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "        index2word = []\n",
    "        if self.pad_token:\n",
    "            index2word.append(self.pad_token)\n",
    "        if self.unk_token:\n",
    "            index2word.append(self.unk_token)\n",
    "\n",
    "        for word, count in sorted_word_counts:\n",
    "            if count < self.min_count or len(index2word) == self.max_vocab_size:\n",
    "                break\n",
    "\n",
    "            index2word.append(word)\n",
    "\n",
    "        word2index = {word: index for index, word in enumerate(index2word)}\n",
    "        return index2word, word2index\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        tokenizer = self.tokenizer_\n",
    "        word2index = self.word2index_\n",
    "        if self.unk_token:\n",
    "            unk_index = word2index[self.unk_token]\n",
    "\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            words = tokenizer(text)\n",
    "            sequence = []\n",
    "            for word in words:\n",
    "                index = word2index.get(word)\n",
    "                if index is not None:\n",
    "                    sequence.append(index)\n",
    "                elif self.unk_token:\n",
    "                    sequence.append(unk_index)\n",
    "\n",
    "            sequences.append(sequence)\n",
    "\n",
    "        return sequences\n",
    "\n",
    "\n",
    "def whitespace_tokenizer(text):\n",
    "    return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rerZGnap28we",
    "outputId": "61c6f6f8-f7ce-4404-ad64-836f8b7f1c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  106145\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(min_count=2)\n",
    "vocab.fit(texts_train)\n",
    "print('vocab size: ', vocab.vocab_size_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1v4AcEHS_KoB"
   },
   "source": [
    "We can plot the distribution of the text length to understand some characteristics about our text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "pC0cKZYt0kbp",
    "outputId": "1be2ce5d-4451-4662-8cf0-64a6a4eea6f5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBQAAALPCAYAAADSNpNKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 359,
       "width": 522
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts_lens = np.array([len(text.split(' ')) for text in texts])\n",
    "\n",
    "# change default style figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.hist(texts_lens)\n",
    "plt.ylabel('')\n",
    "plt.xlabel('text lengths')\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXQFffx7mAXN"
   },
   "source": [
    "This is the part where we should avoid padding the entire text data to a fixed length. Doing so will be suboptimal because when iterating over the dataset in a batched fashion, there will be some batches where the length of all its samples is smaller than the fixed length we've specified. We will deal with padding our tokenized text data in a batch by batch manner later down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsDQlkkf9YAq"
   },
   "outputs": [],
   "source": [
    "tokenized_train = vocab.texts_to_sequences(texts_train)\n",
    "tokenized_val = vocab.texts_to_sequences(texts_val)\n",
    "\n",
    "# in other words, a lot of examples do the following, don't do this\n",
    "# max_len = 72\n",
    "# X_train = pad_sequences(tokenized_train, maxlen=max_len)\n",
    "# X_val = pad_sequences(tokenized_val, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxPvvf3Qj0u9"
   },
   "source": [
    "We now load one of the pre-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXad1R67zr2U"
   },
   "outputs": [],
   "source": [
    "def get_embedding_lookup(embedding_path, embed_size=300, encoding='utf8'):\n",
    "    error_lines = {}\n",
    "    embedding_lookup = {}\n",
    "    with open(embedding_path, encoding=encoding, errors='ignore') as f:\n",
    "        for idx, line in tqdm(enumerate(f)):\n",
    "            try:\n",
    "                values = line.split(' ')\n",
    "                word = values[0]\n",
    "                coef = np.array(values[1:], dtype=np.float32)\n",
    "                if coef.shape[0] != embed_size:\n",
    "                    raise ValueError('embedding size does not match', embed_size)\n",
    "\n",
    "                embedding_lookup[word] = coef\n",
    "            except ValueError:\n",
    "                error_lines[idx] = line\n",
    "\n",
    "    return embedding_lookup, error_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OzkzFjK-zu6f",
    "outputId": "33216ec8-5a6a-4552-fe8c-76eb66928221"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [02:40, 13664.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove embedding vocab size:  2196016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# embedding vocab size : 2,196,016\n",
    "glove_embedding_path = os.path.join(embeddings_dir, 'glove.840B.300d', 'glove.840B.300d.txt')\n",
    "glove_embedding_lookup, glove_error_lines = get_embedding_lookup(glove_embedding_path)\n",
    "print('glove embedding vocab size: ', len(glove_embedding_lookup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTPkwgvdkhnR"
   },
   "source": [
    "Vocabularies that are not found in the pre-trained embeddings are initalized to some random numbers draw from a normal distribution with the mean and standard deviation of the whole pre-trained embedding. The next 2 code chunk computes the mean and standard deviation for the whole pre-trained embedding. Note that in pratice, we can also hard-code these values for pre-trained embeddings that we've already worked with to speed up this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8W4VpLvK_37"
   },
   "outputs": [],
   "source": [
    "def compute_embedding_mean_std(embedding_lookup):\n",
    "    embedding = np.stack(list(embedding_lookup.values()))\n",
    "    return embedding.mean(), embedding.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9PKWDvfwPXwL",
    "outputId": "38e9e3cf-06cd-49dd-9a57-ffd45ec96449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 7.8451313972473145\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# we can replace the computation with hard-coded mean and standardization for the\n",
    "# glove pre-trained embedding\n",
    "glove_embed_mean, glove_embed_std = compute_embedding_mean_std(glove_embedding_lookup)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print('elapsed', elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTxURAiWqucK"
   },
   "source": [
    "The following section highlights one of the main learnings of the competition. So while looking up pre-trained embeddings for our vocabulary, we try using different variations of the word to see if it results in a match. For example, here we capitalize, uppercase, lowercase, use various stemming. The core idea behind it is to make sure we can leverage pre-trained embedding as much as possible, and this approach can be used if we don't have easy access to the preprocessing method that's used by the people that trained the embeddings that we're planning to leverage.\n",
    "\n",
    "There're many ways in which we can preprocess our raw text data. For example, during this competition, a lot of [kernels](https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2) hard-coded a dictionary that contains contraction mappings such as `{\"could've\": \"could have\"}`. Or create custom tokenization rules to split the numbers and punctuations.\n",
    "\n",
    "Creating/preprocessing the vocabulary is an iterative process, if we find that we can increase the coverage by including some additional logic, then we can try and see if it does in fact increase coverage and whether it leads to some downstream performance gain. In this notebook, we just went with spacy tokenizer, use your own personal judgment to measure whether the effort is worth it to go down the customization route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZDEBzrosYMx"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCW6L32q37l2"
   },
   "outputs": [],
   "source": [
    "def get_pretrained_embedding(embedding_lookup, word2index, vocab_size, embed_size, embed_mean, embed_std):\n",
    "    n_vocab_found = 0\n",
    "    embed_shape = (vocab_size, embed_size)\n",
    "    pretrained_embedding = np.random.normal(embed_mean, embed_std, embed_shape).astype(np.float32)\n",
    "    for word, index in word2index.items():\n",
    "        if index >= vocab_size:\n",
    "            continue\n",
    "\n",
    "        embedding_vector = embedding_lookup.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "        # if we can't find the original word in the pre-trained\n",
    "        # embedding lookup, then try different variations to\n",
    "        # see if we can find it.\n",
    "        # There're a lot of duplicated code here that can be polished\n",
    "        embedding_vector = embedding_lookup.get(word.lower())\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "        embedding_vector = embedding_lookup.get(word.upper())\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "        embedding_vector = embedding_lookup.get(word.capitalize())\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "        embedding_vector = embedding_lookup.get(porter_stemmer.stem(word))\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "        embedding_vector = embedding_lookup.get(snowball_stemmer.stem(word))\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "        embedding_vector = embedding_lookup.get(lancaster_stemmer.stem(word))\n",
    "        if embedding_vector is not None:\n",
    "            pretrained_embedding[index] = embedding_vector\n",
    "            n_vocab_found += 1\n",
    "            continue\n",
    "\n",
    "    vocab_found_ratio = n_vocab_found / vocab_size\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(vocab_found_ratio))\n",
    "    return pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4YHtKIGX4iVI",
    "outputId": "ae35947b-8abd-4185-b08e-88219513080d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 94.53% of vocab\n"
     ]
    }
   ],
   "source": [
    "embed_size = 300\n",
    "glove_pretrained_embedding = get_pretrained_embedding(glove_embedding_lookup, vocab.word2index_,\n",
    "                                                      vocab.vocab_size_, embed_size,\n",
    "                                                      glove_embed_mean, glove_embed_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_RDtq5hu42N"
   },
   "source": [
    "This technique is used by the [3rd place kernel](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80495). It even went above and beyond what's implemented here, and tried to perform spell checking, spacy lemmaization to increase of vocabulary coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybnM2zXEEdTg"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-c2DlG2avMv4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojiRPcEvoCz1"
   },
   "source": [
    "The next few code chunk involves understanding how to work with [Pytorch's Dataset and DataLoader](https://pytorch.org/docs/stable/data.html). The main customization that we are doing here is to provide our own implementation of `collate_fn`, where given a batch of dataset, we pad our batch of text data to either the maximum text length that occurs within that data (in the implementation, it contains a parameter to specify the length percentage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Be8OkCn4nBf"
   },
   "outputs": [],
   "source": [
    "class LabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.texts[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBV1c1i84vHp"
   },
   "outputs": [],
   "source": [
    "class LabeledCollate:\n",
    "\n",
    "    def __init__(self, max_len, pad_index, device, percentage=100):\n",
    "        self.device = device\n",
    "        self.max_len = max_len\n",
    "        self.pad_index = pad_index\n",
    "        self.percentage = percentage\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        texts, labels = zip(*batch)\n",
    "\n",
    "        texts_len = [len(text) for text in texts]\n",
    "        texts_len_percentile = int(np.percentile(texts_len, self.percentage))\n",
    "        max_len = min(texts_len_percentile, self.max_len)\n",
    "\n",
    "        padded_texts = pad_sequences(texts, maxlen=max_len, value=self.pad_index)\n",
    "        texts = torch.LongTensor(padded_texts).to(self.device)   \n",
    "        labels = torch.FloatTensor(labels).to(self.device)       \n",
    "        return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kjPKiBjw6GXN",
    "outputId": "4c1eca04-ab38-4602-a093-752dcf8bfc37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding index:  0\n"
     ]
    }
   ],
   "source": [
    "max_len = 72\n",
    "batch_size = 256\n",
    "\n",
    "pad_index = vocab.word2index_[vocab.pad_token]\n",
    "print('padding index: ', pad_index)\n",
    "\n",
    "collate_fn = LabeledCollate(max_len, pad_index, device)\n",
    "dataset_train = LabeledDataset(tokenized_train, y_train)\n",
    "dataset_val = LabeledDataset(tokenized_val, y_val)\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJ1GQJH0qBUW"
   },
   "source": [
    "We can print out one batch from the dataloader to confirm the size/shape\n",
    "is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "gWpe2NXI6Hs4",
    "outputId": "11ad8d90-00ae-4e2c-c82e-2009ef440428"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ...,    33, 34125,     1],\n",
       "        [    0,     0,     0,  ..., 47667,   428,     1],\n",
       "        [    0,     0,     0,  ...,    15,   352,     1],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,   251,  8690,     1],\n",
       "        [    0,     0,     0,  ...,     9,  1367,     1],\n",
       "        [    0,     0,     0,  ...,  1606, 56350,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(data_loader_val))\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bIRZMeTHZ_Bm",
    "outputId": "cebcebaa-1e18-4286-83e6-d29fe5130357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 54])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckqn3Fn-Eas2"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WVi2bGj_qzmj"
   },
   "source": [
    "Deep learning frameworks gives us the flexibility to define the [architectures](https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/) suitable for the text classification task at hand. During this competition, popular architectures include Bi-Directional LSTM/GRU and attention layer.\n",
    "\n",
    "The idea behind attention mechanism is that not all words in the sentence contribute equally to the task. Hence, we introduce an attention layer within our architecture so that the model can learn when does a word contribute more to the prediction.\n",
    "\n",
    "Please refer to the following paper for more context.\n",
    "[Paper: Z. Yang, D. Tang, C. Dyer, X. He, A, Smola, E. Hovy - Hierarchical Attention Networks for Document Classification (2016)](https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VnUxDxeLA4o"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    A lot of examples on the internet implements the attention layer without\n",
    "    the context vector, which is different from the notation that is mentioned\n",
    "    in the paper hierachical attention network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_size):\n",
    "        super().__init__()\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "        self.weight = nn.Linear(feature_size, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs : [batch size, sequence len, hidden size * num directions]\n",
    "        seq_len = inputs.shape[1]\n",
    "        reshaped_inputs = inputs.contiguous().view(-1, self.feature_size)\n",
    "\n",
    "        # [batch size, sequence len]\n",
    "        uit = torch.tanh(self.weight(reshaped_inputs)).view(-1, seq_len)\n",
    "\n",
    "        # [batch size, sequence len]\n",
    "        ait = torch.softmax(uit, dim=-1)\n",
    "        # [batch size, sequence len, 1]\n",
    "        ait_reshaped = torch.unsqueeze(ait, dim=-1)\n",
    "\n",
    "        # [batch size, hidden layer]\n",
    "        weighted_inputs = torch.sum(ait_reshaped * inputs, dim=1)\n",
    "        return weighted_inputs, ait\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'feature_size={}'.format(self.feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOd70Z_bfB8V"
   },
   "outputs": [],
   "source": [
    "class AttentionWithContext(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size, attention_size):\n",
    "        super().__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.attention_size = attention_size\n",
    "\n",
    "        self.weight = nn.Linear(feature_size, attention_size)\n",
    "        self.context = nn.Linear(attention_size, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs : [batch size, sequence len, hidden size * num directions]\n",
    "        seq_len = inputs.shape[1]\n",
    "        reshaped_inputs = inputs.contiguous().view(-1, self.feature_size)\n",
    "\n",
    "        # [batch size * sequence len, attention size]\n",
    "        uit = torch.tanh(self.weight(reshaped_inputs))\n",
    "\n",
    "        # [batch size, sequence len]\n",
    "        ait = self.context(uit).view(-1, seq_len)\n",
    "\n",
    "        # [batch size, sequence len]\n",
    "        ait = torch.softmax(ait, dim=-1)\n",
    "        # [batch size, sequence len, 1]\n",
    "        ait_reshaped = torch.unsqueeze(ait, dim=-1)\n",
    "\n",
    "        # [batch size, hidden layer]\n",
    "        weighted_inputs = torch.sum(ait_reshaped * inputs, dim=1)\n",
    "        return weighted_inputs, ait\n",
    "\n",
    "    def extra_repr(self):\n",
    "        repr_str = 'feature_size={}, attention_size={}'\n",
    "        return repr_str.format(self.feature_size, self.attention_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKmA135cjBLe"
   },
   "outputs": [],
   "source": [
    "class TextAttentionLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, vocab_size=None, embed_size=300,\n",
    "                 n_layers=2, hidden_size=128, linear_size=256, attention_size=100,\n",
    "                 pretrained_embedding=None, freeze=True):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_size = linear_size\n",
    "        self.attention_size = attention_size\n",
    "\n",
    "        if pretrained_embedding is None:\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "            self.vocab_size = vocab_size\n",
    "            self.embed_size = embed_size\n",
    "        else:\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(pretrained_embedding), freeze=freeze)\n",
    "            self.vocab_size = self.embedding.num_embeddings\n",
    "            self.embed_size = self.embedding.embedding_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(self.embed_size, hidden_size, n_layers, bidirectional=True, batch_first=True)\n",
    "        self.attention = AttentionWithContext(hidden_size * 2, attention_size)\n",
    "        self.linear = nn.Linear(hidden_size * 2, linear_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(linear_size, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        output, _ = self.forward_with_attention(text)\n",
    "        return output\n",
    "\n",
    "    def forward_with_attention(self, text):\n",
    "        # embedded : [batch size, sent len, embed size]\n",
    "        embedded = self.embedding(text)\n",
    "        # output : [batch size, sent len, hidden size * num directions]\n",
    "        # hidden : [n layers * n directions, batch size, hidden size]\n",
    "        lstm_outputs, (lstm_hidden, lstm_cell) = self.lstm(embedded)\n",
    "        weighted_lstm_outputs, attention = self.attention(lstm_outputs)\n",
    "        dense = self.relu(self.linear(weighted_lstm_outputs))\n",
    "        output = self.output(dense)\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wld0Gde3U-56"
   },
   "outputs": [],
   "source": [
    "class TextLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, vocab_size=None, embed_size=300,\n",
    "                 n_layers=2, hidden_size=128, linear_size=256,\n",
    "                 pretrained_embedding=None, freeze=True):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_size = linear_size\n",
    "\n",
    "        if pretrained_embedding is None:\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "            self.vocab_size = vocab_size\n",
    "            self.embed_size = embed_size\n",
    "        else:\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(pretrained_embedding), freeze=freeze)\n",
    "            self.vocab_size = self.embedding.num_embeddings\n",
    "            self.embed_size = self.embedding.embedding_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(self.embed_size, hidden_size, n_layers, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size * 2, linear_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(linear_size, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # embedded : [batch size, sent len, embed size]\n",
    "        embedded = self.embedding(text)\n",
    "        # output : [batch size, sent len, hidden size * num directions]\n",
    "        # hidden : [n layers * n directions, batch size, hidden size]\n",
    "        lstm_outputs, (lstm_hidden, lstm_cell) = self.lstm(embedded)\n",
    "        concated = torch.cat((lstm_hidden[-2, :, :], lstm_hidden[-1, :, :]), dim=1)\n",
    "        dense = self.relu(self.linear(concated))\n",
    "        output = self.output(dense)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "L5TlB3RQVLN2",
    "outputId": "5c43f9a9-3aa8-4b06-9af2-e805fb0065b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextAttentionLSTM(\n",
       "  (embedding): Embedding(106145, 300)\n",
       "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (attention): AttentionWithContext(feature_size=256)\n",
       "  (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = 1\n",
    "\n",
    "# both gave similar performance for this task\n",
    "# glove_model = TextLSTM(num_class, pretrained_embedding=glove_pretrained_embedding).to(device)\n",
    "glove_model = TextAttentionLSTM(num_class, pretrained_embedding=glove_pretrained_embedding).to(device)\n",
    "glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kT0AhBNV2ioo",
    "outputId": "08d3ec3e-5011-47f7-fdbb-e7951df14e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 927,333 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(glove_model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V719tgTQrYLA"
   },
   "source": [
    "The next couple of code chunks involves defining functions to train the model, while training the model, we've although pass in the validation set to perform early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6cisi-uvMwG"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_output = model(x_batch).squeeze(dim=1)\n",
    "        loss = criterion(y_output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = binary_accuracy(y_output, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DKJyFUNJ4sK"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y_output, y_true):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    # round predictions to the closest integer/label\n",
    "    rounded_preds = torch.round(torch.sigmoid(y_output))\n",
    "    correct = (rounded_preds == y_true).float()\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbpWck2rusze"
   },
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            y_output = model(x_batch).squeeze(dim=1)\n",
    "            loss = criterion(y_output, y_batch)\n",
    "            acc = binary_accuracy(y_output, y_batch)\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmKJguZsJMrc"
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader_train, data_loader_val, criterion, optimizer,\n",
    "          epochs=10, max_patience=1, model_checkpoint='model.pt'):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_epoch(model, data_loader_train, criterion, optimizer)\n",
    "        val_loss, val_acc = evaluate_epoch(model, data_loader_val, criterion)\n",
    "\n",
    "        secs = int(time.time() - start_time)\n",
    "        mins = secs / 60\n",
    "        secs = secs % 60\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            patience = 0\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_checkpoint)\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience > max_patience:\n",
    "                break\n",
    "\n",
    "        print('Epoch %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "        print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "        print(f'\\tLoss: {val_loss:.4f}(val)\\t|\\tAcc: {val_acc * 100:.1f}%(val)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "AMkCiJwryjjo",
    "outputId": "d130db32-ba63-413b-ca77-dbc0ca6d1885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  | time in 1 minutes, 49 seconds\n",
      "\tLoss: 0.1119(train)\t|\tAcc: 95.6%(train)\n",
      "\tLoss: 0.1022(val)\t|\tAcc: 95.9%(val)\n",
      "Epoch 2  | time in 1 minutes, 48 seconds\n",
      "\tLoss: 0.0972(train)\t|\tAcc: 96.1%(train)\n",
      "\tLoss: 0.0978(val)\t|\tAcc: 96.1%(val)\n",
      "Epoch 3  | time in 1 minutes, 49 seconds\n",
      "\tLoss: 0.0897(train)\t|\tAcc: 96.4%(train)\n",
      "\tLoss: 0.0964(val)\t|\tAcc: 96.2%(val)\n",
      "Epoch 4  | time in 1 minutes, 44 seconds\n",
      "\tLoss: 0.0822(train)\t|\tAcc: 96.7%(train)\n",
      "\tLoss: 0.0970(val)\t|\tAcc: 96.2%(val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(glove_model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "glove_model_checkpoint = 'glove.pt'\n",
    "\n",
    "train(glove_model, data_loader_train, data_loader_val, criterion, optimizer,\n",
    "      model_checkpoint=glove_model_checkpoint)\n",
    "\n",
    "glove_model.load_state_dict(torch.load(glove_model_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHzg82T30Z5J"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTGMCzvdrtVe"
   },
   "source": [
    "The prediction part is somewhat similar to what we've did in the previous section. We tokenize the raw text from the test data, convert them into indices, then generate the predicted score for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OGdCAzqcCYd4",
    "outputId": "303488f9-be2f-4371-c261-cff122751259"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375806/375806 [01:59<00:00, 3150.76it/s]\n"
     ]
    }
   ],
   "source": [
    "texts_test = []\n",
    "for text in tqdm(df_test[text_col]):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    tokenized_text = ' '.join(token.text for token in doc)\n",
    "    texts_test.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JdKOSWbZ-Fa4"
   },
   "outputs": [],
   "source": [
    "tokenized_test = vocab.texts_to_sequences(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLAy4xX2bsfh"
   },
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "\n",
    "class UnlabeledCollate:\n",
    "\n",
    "    def __init__(self, max_len, pad_index, device, percentage=100):\n",
    "        self.device = device\n",
    "        self.max_len = max_len\n",
    "        self.pad_index = pad_index\n",
    "        self.percentage = percentage\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        texts_len = [len(text) for text in batch]\n",
    "        texts_len_percentile = int(np.percentile(texts_len, self.percentage))\n",
    "        max_len = min(texts_len_percentile, self.max_len)\n",
    "\n",
    "        padded_batch = pad_sequences(batch, maxlen=max_len, value=self.pad_index)\n",
    "        texts = torch.LongTensor(padded_batch).to(self.device)      \n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PeNFrqQAuYY"
   },
   "outputs": [],
   "source": [
    "def predict(model, X, pad_index, batch_size=512):\n",
    "    dataset = UnlabeledDataset(X)\n",
    "    collate_fn = UnlabeledCollate(max_len, pad_index, device)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "    n_rows = len(X)\n",
    "    predictions = np.zeros(n_rows)\n",
    "    with torch.no_grad():\n",
    "        idx = 0\n",
    "        for x_batch in data_loader:\n",
    "            y_output = model(x_batch).squeeze(dim=1)\n",
    "            y_score = torch.sigmoid(y_output).cpu().numpy()\n",
    "\n",
    "            start_idx = idx\n",
    "            idx += batch_size\n",
    "            end_idx = idx\n",
    "            predictions[start_idx:end_idx] = y_score\n",
    "\n",
    "            if end_idx == n_rows:\n",
    "                break\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ix261l7DCxrg",
    "outputId": "52224dac-a3dd-46a6-ef34-5f9e3346098e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.98427260e-01, 1.45648824e-04, 3.81290098e-04, ...,\n",
       "       9.16973106e-04, 4.65367993e-05, 8.34513903e-02])"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = predict(glove_model, tokenized_test, pad_index)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqlTtJrtRfuv"
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5JUwQUBfs-tE"
   },
   "source": [
    "Generating the submission involves finding the threshold that reaches the optimal f1 score on the validation set then using that threshold to generated the prediction label on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sANjCWoyRhcd"
   },
   "outputs": [],
   "source": [
    "def create_submission(ids, predictions, ids_col, prediction_col, submission_path) -> pd.DataFrame:\n",
    "    df_submission = pd.DataFrame({\n",
    "        ids_col: ids,\n",
    "        prediction_col: predictions\n",
    "    }, columns=[ids_col, prediction_col])\n",
    "\n",
    "    if submission_path is not None:\n",
    "        # create the directory if need be, e.g. if the submission_path = submission/submission.csv\n",
    "        # we'll create the submission directory first if it doesn't exist\n",
    "        directory = os.path.split(submission_path)[0]\n",
    "        if (directory != '' or directory != '.') and not os.path.isdir(directory):\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        df_submission.to_csv(submission_path, index=False, header=True)\n",
    "\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECHU1E3jRkGm"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def compute_score(y_true, y_score, verbose=True, round_digits=3):\n",
    "\n",
    "    log_loss = round(metrics.log_loss(y_true, y_score), round_digits)\n",
    "\n",
    "    precision, recall, threshold = metrics.precision_recall_curve(y_true, y_score)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    mask = ~np.isnan(f1)\n",
    "    f1 = f1[mask]\n",
    "    precision = precision[mask]\n",
    "    recall = recall[mask]\n",
    "\n",
    "    best_index = np.argmax(f1)\n",
    "    threshold = round(threshold[best_index], round_digits)\n",
    "    precision = round(precision[best_index], round_digits)\n",
    "    recall = round(recall[best_index], round_digits)\n",
    "    f1 = round(f1[best_index], round_digits)\n",
    "\n",
    "    if verbose:\n",
    "        print('threshold: ', threshold)\n",
    "        print('precision: ', precision)\n",
    "        print('recall: ', recall)\n",
    "        print('f1: ', f1)\n",
    "\n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'log_loss': log_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YY78LciZVx-h"
   },
   "outputs": [],
   "source": [
    "ids_col = 'qid'\n",
    "prediction_col = 'prediction'\n",
    "ids = df_test[ids_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "U3mtAkJZV0d3",
    "outputId": "1fbd4aba-8e57-4a22-e377-06398ff12bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating submission\n",
      "threshold:  0.349\n",
      "precision:  0.672\n",
      "recall:  0.712\n",
      "f1:  0.691\n",
      "(375806, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           1\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained-embedding : glove f1 0.69\n",
    "# no-pre-trained f1: 0.652\n",
    "print('generating submission')\n",
    "submission_path = os.path.join(submission_dir, 'submission.csv')\n",
    "\n",
    "y_pred_val = predict(glove_model, tokenized_val, pad_index)\n",
    "score_dict = compute_score(y_val, y_pred_val)\n",
    "\n",
    "y_pred_test = predict(glove_model, tokenized_test, pad_index)\n",
    "predictions = (y_pred_test > score_dict['threshold']).astype(np.int)\n",
    "df_submission = create_submission(ids, predictions, ids_col, prediction_col, submission_path)\n",
    "\n",
    "# sanity check to make sure the size and the output of the submission makes sense\n",
    "print(df_submission.shape)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNknb6SZ6eg8"
   },
   "source": [
    "The goal of this notebook was to introduce some of the biggest personal learnings/gains from the competition. We've achieved a f1 score of 0.69 on the validation set without getting into the ensembling territory.\n",
    "\n",
    "There're other techniques that were seen in the discussion forum that can be worth trying if we wish to reproduce the performance of the winners.\n",
    "\n",
    "- Checkpoint ensembling. The idea is to perform some weighted average of the predictions after different epoch. e.g. The predictions can be 0.3 of the model from the 4th epoch and 0.7 of the model from the 5th epoch.\n",
    "- Meta Embedding. There're many pre-trained embeddings available, and each one of them might contain unique information, hence a lot of the winning solutions used some weighted version of multiple embeddings or even concatenated the pre-trained embeddings. The term meta embedding refers to ensembling multiple pret-trained embeddings. There're even works on dymanically determining the best weighting of multiple pre-trained embeddings. [Github: Dynamic Meta-Embeddings for Improved Sentence Representations](https://github.com/facebookresearch/DME)\n",
    "- Model Architecture. Adding statistical features have been reported to have some gains on the performance. These can include length of the text, question that starts with why, number of words v.s. unique words etc. These statistical features are fed into a dense layer then concatenated together with the output layer from the raw text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWSwVRfXI2CR"
   },
   "source": [
    "# Reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVKm3ZzpI4Rs"
   },
   "source": [
    "- [Kaggle: Quora Insincere Questions Classification - 3rd place kernel](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80495)\n",
    "- [Kaggle: Quora Insincere Questions Classification - 1st place solution](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568)\n",
    "- [Kaggle: Jigsaw Unintended Bias in Toxicity Classification - Speed up your RNN with Sequence Bucketing](https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing)\n",
    "- [Blog: What my first Silver Medal taught me about Text Classification and Kaggle in general?](https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/)\n",
    "- [Blog: NLP Learning Series: Part 3 - Attention, CNN and what not for Text Classification](https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/)\n",
    "- [Blog: Text Classification, Part 3 - Hierarchical attention network](https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-HATN/)\n",
    "- [Paper: Z. Yang, D. Tang, C. Dyer, X. He, A, Smola, E. Hovy - Hierarchical Attention Networks for Document Classification (2016)](https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pytorch_quora_insincere.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
